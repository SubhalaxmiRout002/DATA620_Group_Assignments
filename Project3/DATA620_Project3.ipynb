{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUNY Data 620 - Web Analytics, Summer 2020  \n",
    "**Group Project 3**   \n",
    "**Prof:** Alain Ledon  \n",
    "**Members:** Misha Kollontai, Amber Ferger, Zach Alexander, Subhalaxmi Rout  \n",
    "  \n",
    "**YouTube Link**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python,\n",
    "and any features you can think of, build the best name gender classifier you can. \n",
    "\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the devtest set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "\n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what\n",
    "you'd expect? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The *names* corpus in the nltk package contains the names and genders of 7,944 individuals. First, we will compile a list of all names with their gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2943 male names in the dataset.\n",
      "There are 5001 female names in the dataset.\n"
     ]
    }
   ],
   "source": [
    "males = [(name, 'male') for name in names.words('male.txt')]\n",
    "numMales = len(males)\n",
    "females = [(name, 'female') for name in names.words('female.txt')]\n",
    "numFemales = len(females)\n",
    "\n",
    "print(f'There are {numMales} male names in the dataset.')\n",
    "print(f'There are {numFemales} female names in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the lists and shuffle the data so that all names of the same gender are not together. We can confirm that the names are shuffled by looking at the genders of the first 5 individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 names in the dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Cordelie', 'female'),\n",
       " ('Peggie', 'female'),\n",
       " ('Solange', 'female'),\n",
       " ('Rana', 'female'),\n",
       " ('Jessy', 'female')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(123)\n",
    "allNames = males + females\n",
    "random.shuffle(allNames)\n",
    "\n",
    "print('First 5 names in the dataset:')\n",
    "allNames[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Features\n",
    "Next, we'll define a function to create features for our names. The initial features will include:\n",
    "* **last_letter**: The last letter of the given name.\n",
    "* **first_letter**: The first letter of the given name. \n",
    "* **name_length**: The length of the given name.\n",
    "* **num_vowels**: The number of vowels in the given name.\n",
    "* **num_consonants**: The number of consonants in the given name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)  \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split\n",
    "Now that we've defined our feature function, we can run it on our dataset and split it into training, testing, and dev testing sets. \n",
    "* **Training Set**: This data will be used to train our classifiers and fit the models.\n",
    "* **Dev Test Set**: This data will be used to predict the gender (male or female). It will provide an unbiased evaluation of a model fit on the training dataset. We can use the results of the development set to tune our model. \n",
    "* **Test Set**: This data will be used to compute the accuracy of the final model. Since the model has never seen this data, it will provide an unbiased evaluation of the clasifier.\n",
    "\n",
    "The splits will be in the format of ({features}, gender). We will store the names and genders of the individuals in separate lists for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num records - train set:  6944\n",
      "Num records - dev test set:  500\n",
      "Num records - test set:  500\n"
     ]
    }
   ],
   "source": [
    "def tts(featureFunc, nameList):\n",
    "    featureSet = [(featureFunc(n),g) for (n,g) in nameList]\n",
    "    test_set, devtest_set, train_set = featureSet[0:500], featureSet[500:1000], featureSet[1000:] \n",
    "    tsName = nameList[0:500]\n",
    "    dtName = nameList[500:1000]\n",
    "    tName = nameList[1000:]\n",
    "    \n",
    "    return test_set, devtest_set, train_set, tsName, dtName, tName\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features, allNames)\n",
    "\n",
    "print('Num records - train set: ', len(train_set))\n",
    "print('Num records - dev test set: ', len(devtest_set))\n",
    "print('Num records - test set: ', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Classifier - Naive Bayes Classifier\n",
    "Now that we've split our data into training, development, and test sets, we can create a **Naive Bayes Classifier** to predict the gender of the names. In this type of model, each feature gets a say in determining which label should be assigned to a given input value. The prior probability is calculated for each label (male, female), and the contribution from each feature is combined with this probability to arrive at a likelihood estimate for each label.\n",
    "\n",
    "We will measure the accuracy of the model (the percentage of names the classifier predicts correctly) using the development test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.782\n"
     ]
    }
   ],
   "source": [
    "nbClass = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the most important features used for predicting the gender. For each feature, this tells us the ratio of occurences for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.3 : 1.0\n",
      "             last_letter = 'k'              male : female =     29.2 : 1.0\n",
      "             last_letter = 'p'              male : female =     18.6 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.2 : 1.0\n",
      "             last_letter = 'v'              male : female =      9.8 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.8 : 1.0\n",
      "             last_letter = 'm'              male : female =      9.2 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.0 : 1.0\n",
      "             last_letter = 'w'              male : female =      8.0 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.7 : 1.0\n",
      "            first_letter = 'w'              male : female =      4.6 : 1.0\n",
      "              num_vowels = 5              female : male   =      4.5 : 1.0\n",
      "             last_letter = 'b'              male : female =      4.4 : 1.0\n",
      "             last_letter = 's'              male : female =      4.3 : 1.0\n",
      "             last_letter = 'g'              male : female =      4.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nbClass.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the last letter and number of vowels in the names appear to be the driving factors. \n",
    "\n",
    "We can also generate a list of errors to see which names we've classified improperly. This will help us identify what additional features we should add to make the classification more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 109\n"
     ]
    }
   ],
   "source": [
    "def pred_calc(nameList, featureFunc, nbClass):\n",
    "    preds = []\n",
    "    errors = []\n",
    "    for (name,actual) in nameList:\n",
    "        guess = nbClass.classify(featureFunc(name))\n",
    "        preds.append((actual,guess,name))\n",
    "        if guess != actual:\n",
    "            errors.append((actual, guess, name))\n",
    "    \n",
    "    return preds, errors\n",
    "\n",
    "preds, errors = pred_calc(dtName, gender_features, nbClass)\n",
    "print('Number of errors:', len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we sort the errors by the last two characters of the first name, we can see that some combinations occur more frequently in males than females and vice versa. For example, the letters *ie* appear more often in male names and then letters *ly* appear more often in female names. Let's update our feature set to take this into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('female', 'male', 'Em'),\n",
       " ('female', 'male', 'Talyah'),\n",
       " ('female', 'male', 'Shirah'),\n",
       " ('male', 'female', 'Donal'),\n",
       " ('female', 'male', 'Sam'),\n",
       " ('male', 'female', 'Fabian'),\n",
       " ('female', 'male', 'Sean'),\n",
       " ('male', 'female', 'Coleman'),\n",
       " ('male', 'female', 'Christian'),\n",
       " ('male', 'female', 'Adrian'),\n",
       " ('male', 'female', 'Vaughan'),\n",
       " ('female', 'male', 'Meggan'),\n",
       " ('female', 'male', 'Gay'),\n",
       " ('male', 'female', 'Murray'),\n",
       " ('male', 'female', 'Lawrence'),\n",
       " ('male', 'female', 'Bruce'),\n",
       " ('male', 'female', 'Lawerence'),\n",
       " ('male', 'female', 'Erich'),\n",
       " ('female', 'male', 'Dulcy'),\n",
       " ('male', 'female', 'Randi'),\n",
       " ('male', 'female', 'Lindy'),\n",
       " ('female', 'male', 'Freddy'),\n",
       " ('male', 'female', 'Jessee'),\n",
       " ('male', 'female', 'Mikel'),\n",
       " ('male', 'female', 'Nathaniel'),\n",
       " ('female', 'male', 'Pen'),\n",
       " ('female', 'male', 'Gwen'),\n",
       " ('female', 'male', 'Grier'),\n",
       " ('female', 'male', 'Delores'),\n",
       " ('female', 'male', 'Dew'),\n",
       " ('female', 'male', 'Sukey'),\n",
       " ('male', 'female', 'Carey'),\n",
       " ('female', 'male', 'Sophey'),\n",
       " ('female', 'male', 'Sibley'),\n",
       " ('female', 'male', 'Daffy'),\n",
       " ('male', 'female', 'Rutledge'),\n",
       " ('female', 'male', 'Margo'),\n",
       " ('female', 'male', 'Angy'),\n",
       " ('male', 'female', 'Jean-Christophe'),\n",
       " ('male', 'female', 'Sollie'),\n",
       " ('male', 'female', 'Christie'),\n",
       " ('male', 'female', 'Georgie'),\n",
       " ('male', 'female', 'Bobbie'),\n",
       " ('male', 'female', 'Kermie'),\n",
       " ('male', 'female', 'Dennie'),\n",
       " ('male', 'female', 'Pennie'),\n",
       " ('male', 'female', 'Maurie'),\n",
       " ('male', 'female', 'Rickie'),\n",
       " ('female', 'male', 'Charin'),\n",
       " ('female', 'male', 'Devin'),\n",
       " ('female', 'male', 'Cristin'),\n",
       " ('female', 'male', 'Shir'),\n",
       " ('female', 'male', 'Wandis'),\n",
       " ('female', 'male', 'Maris'),\n",
       " ('male', 'female', 'Thorndike'),\n",
       " ('male', 'female', 'Ricki'),\n",
       " ('female', 'male', 'Tomiko'),\n",
       " ('female', 'male', 'Vicky'),\n",
       " ('male', 'female', 'Gayle'),\n",
       " ('male', 'female', 'Yale'),\n",
       " ('male', 'female', 'Beale'),\n",
       " ('male', 'female', 'Pascale'),\n",
       " ('male', 'female', 'Emile'),\n",
       " ('female', 'male', 'Merrill'),\n",
       " ('female', 'male', 'Joly'),\n",
       " ('female', 'male', 'Hally'),\n",
       " ('female', 'male', 'Vally'),\n",
       " ('female', 'male', 'Holly'),\n",
       " ('male', 'female', 'Baily'),\n",
       " ('male', 'female', 'Guillaume'),\n",
       " ('male', 'female', 'Tome'),\n",
       " ('female', 'male', 'Clemmy'),\n",
       " ('male', 'female', 'Zane'),\n",
       " ('male', 'female', 'Simone'),\n",
       " ('male', 'female', 'Dani'),\n",
       " ('female', 'male', 'Jo-Ann'),\n",
       " ('female', 'male', 'Quinn'),\n",
       " ('female', 'male', 'Melicent'),\n",
       " ('female', 'male', 'Vonny'),\n",
       " ('female', 'male', 'Vinny'),\n",
       " ('female', 'male', 'Penny'),\n",
       " ('female', 'male', 'Rhianon'),\n",
       " ('female', 'male', 'Rhiamon'),\n",
       " ('male', 'female', 'Ferguson'),\n",
       " ('female', 'male', 'Leanor'),\n",
       " ('female', 'male', 'Charlot'),\n",
       " ('male', 'female', 'Eliot'),\n",
       " ('female', 'male', 'Harriot'),\n",
       " ('male', 'female', 'Phillipe'),\n",
       " ('male', 'female', 'Demetre'),\n",
       " ('male', 'female', 'Henri'),\n",
       " ('female', 'male', 'Merl'),\n",
       " ('female', 'male', 'Gert'),\n",
       " ('female', 'male', 'Dory'),\n",
       " ('female', 'male', 'Gerry'),\n",
       " ('male', 'female', 'Maurise'),\n",
       " ('female', 'male', 'Lindsy'),\n",
       " ('male', 'female', 'Juanita'),\n",
       " ('male', 'female', 'Durante'),\n",
       " ('female', 'male', 'Janith'),\n",
       " ('female', 'male', 'Marybeth'),\n",
       " ('female', 'male', 'Helen-Elizabeth'),\n",
       " ('male', 'female', 'Morty'),\n",
       " ('female', 'male', 'Fawn'),\n",
       " ('male', 'female', 'Saxe'),\n",
       " ('female', 'male', 'Jesselyn'),\n",
       " ('female', 'male', 'Marilyn'),\n",
       " ('female', 'male', 'Roselyn'),\n",
       " ('female', 'male', 'Ardys')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(errors, key=lambda x: x[-1][-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set Revamp\n",
    "\n",
    "**Last two letters**: First, let's add in a feature for the last 2 letters of each name. We'll recreate our train, test, and dev test splits and run the Naive Bayes Classifer on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.82\n",
      "Number of errors: 90\n"
     ]
    }
   ],
   "source": [
    "def gender_features2(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "    \n",
    "    # add in feature for last 2 letters of name\n",
    "    features['last_two_letters'] = name[-2:]\n",
    "    \n",
    "    # add in feature for first 2 letters of name\n",
    "    features['first_two_letters'] = name[:2]\n",
    "    \n",
    "    # presence of double letters:\n",
    "    def find_dbl_ltrs(x):\n",
    "        groups = groupby(name)\n",
    "        result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "        return (len([x[1] for x in result if x[1]>1]))\n",
    "    features['dbl_ltrs'] = find_dbl_ltrs(name)\n",
    "\n",
    "    return features\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features2, allNames)\n",
    "nbClass2 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass2, devtest_set))\n",
    "\n",
    "preds2, errors2 = pred_calc(dtName, gender_features2, nbClass2)\n",
    "print('Number of errors:', len(errors2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy went up to 82%! Let's try again with some additional features.\n",
    "\n",
    "**Bouba and Kiki Vowels/Consonants**: Sidhu and Pexman (1) discovered a relationship of Bouba with female first names and Kiki with male first names. We will use a modified version of their findings and define the following new features: \n",
    "* **num_bouba_cons**: Count of the letters *b*, *l*, *m*, and *n*. *(Female names tend to have more of these)*\n",
    "* **num_bouba_vowels**: Count of the letters *u* and *o*. *(Female names tend to have more of these)*\n",
    "* **num_kiki_cons**: Count of the letters *k*, *p*, and *t*. *(Male names tend to have more of these)*\n",
    "* **num_kiki_vowels**: Count of the letters *i* and *e*. *(Male names tend to have more of these)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.81\n"
     ]
    }
   ],
   "source": [
    "# https://arxiv.org/pdf/1606.05467.pdf\n",
    "\n",
    "def gender_features3(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "    \n",
    "    # add in feature for last 2 letters of name\n",
    "    features['last_two_letters'] = name[-2:]\n",
    "    \n",
    "    # add in feature for first 2 letters of name\n",
    "    features['first_two_letters'] = name[:2]\n",
    "    \n",
    "    # presence of double letters:\n",
    "    def find_dbl_ltrs(x):\n",
    "        groups = groupby(name)\n",
    "        result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "        return (len([x[1] for x in result if x[1]>1]))\n",
    "    features['dbl_ltrs'] = find_dbl_ltrs(name)\n",
    "    \n",
    "    # add in bouba & kiki counts\n",
    "    boubaCons = ['b', 'l', 'm', 'n']\n",
    "    boubaVowels = ['u', 'o']\n",
    "    kikiCons = ['k', 'p', 't']\n",
    "    kikiVowels = ['i', 'e']\n",
    "    \n",
    "    bcLength = len([i for i in name if i in boubaCons])\n",
    "    bvLength = len([i for i in name if i in boubaVowels])\n",
    "    kcLength = len([i for i in name if i in kikiCons])\n",
    "    kvLength = len([i for i in name if i in kikiVowels])\n",
    "\n",
    "    features['num_bouba_cons'] = bcLength\n",
    "    features['num_bouba_vowels'] = bvLength\n",
    "    features['num_kiki_cons'] = kcLength\n",
    "    features['num_kiki_vowels'] = kvLength\n",
    "\n",
    "    return features\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "nbClass3 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass3, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 95\n"
     ]
    }
   ],
   "source": [
    "preds3, errors3 = pred_calc(dtName, gender_features3,nbClass3)\n",
    "print('Number of errors:', len(errors3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We can now evaluate the final model on our test set. First, we'll look at the overall accuracy of each of our subsequent models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>DEV_ACCURACY</th>\n",
       "      <th>TEST_ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Second</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Final</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MODEL  DEV_ACCURACY  TEST_ACCURACY\n",
       "0   First         0.782          0.772\n",
       "1  Second         0.820          0.800\n",
       "2   Final         0.810          0.802"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['First', nltk.classify.accuracy(nbClass, devtest_set), nltk.classify.accuracy(nbClass, test_set)], \n",
    "             ['Second', nltk.classify.accuracy(nbClass2, devtest_set), nltk.classify.accuracy(nbClass2, test_set)], \n",
    "             ['Final', nltk.classify.accuracy(nbClass3, devtest_set), nltk.classify.accuracy(nbClass3, test_set)]],\n",
    "            columns = ['MODEL', 'DEV_ACCURACY', 'TEST_ACCURACY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy on the development and test set increases from the first model to the final model. When looking at each model, we also notice that the accuracy on the test set is lower than on the development set. This is expected, as we tweaked our feature set based on the results of the development set and the test set contains data that the model has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtPred, dtError = pred_calc(dtName, gender_features3,nbClass3)\n",
    "tsPred, tsError = pred_calc(tsName, gender_features3,nbClass3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summ_table(allNames, tsPred):\n",
    "    tag = [name for name in tsPred if [name for (name, tag) in allNames]]\n",
    "    perform = []\n",
    "    for i in tsPred:\n",
    "        if (i[0] == 'male') & (i[1] == 'male'):\n",
    "            perform.append('correct male')\n",
    "        elif (i[0] == 'female') & (i[1] == 'female'):\n",
    "            perform.append('correct female')\n",
    "        elif (i[0] == 'male') & (i[1] == 'female'):\n",
    "            perform.append('incorrect male')\n",
    "        else:\n",
    "            perform.append('incorrect female')\n",
    "    correct_male = perform.count('correct male')\n",
    "    correct_female = perform.count('correct female')\n",
    "    incorrect_female = perform.count('incorrect female')\n",
    "    incorrect_male = perform.count('incorrect male')\n",
    "    \n",
    "    performance_table = pd.DataFrame([['Females', correct_female, incorrect_female],\n",
    "             ['Males', correct_male, incorrect_male]],\n",
    "            columns = ['Gender', 'Correct Predictions', 'Incorrect Predictions'])\n",
    "    performance_table.style.hide_index()\n",
    "    performance_table_pct = pd.DataFrame([['Females', \"{:.0%}\".format(correct_female / (correct_female + incorrect_female)), \"{:.0%}\".format(incorrect_female / (correct_female + incorrect_female))],\n",
    "             ['Males', \"{:.0%}\".format(correct_male / (correct_male + incorrect_male)), \"{:.0%}\".format(incorrect_male / (correct_male + incorrect_male))]],\n",
    "            columns = ['Gender', 'Percent Correct', 'Percent Incorrect'])\n",
    "    performance_table_pct.style.hide_index()\n",
    "    \n",
    "    return performance_table_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then wanted to take a look at the relative accuracies with respect to the two genders. The table below breaks down the results of our final model. It shows that our model predicted female names with a greater accuracy than male names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Percent Correct</th>\n",
       "      <th>Percent Incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Females</td>\n",
       "      <td>83%</td>\n",
       "      <td>17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Males</td>\n",
       "      <td>76%</td>\n",
       "      <td>24%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Percent Correct Percent Incorrect\n",
       "0  Females             83%               17%\n",
       "1    Males             76%               24%"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_table_pct = summ_table(allNames, tsPred)\n",
    "performance_table_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the better accuracy for female names, we remembered that the dataset is skewed fairly heavily in favor of female names (63% female / 37% male). In order to see how much the greater accuracy for female names was driven by the disbalance within the dataset we decided to try two basic approaches of dealing with an imbalanced dataset: Undersampling and Oversampling. We decided to re-evaluate our model after adjusting the training data to be balanced - once by removing the extra female names and once by copying in repeats of male names to balance out the number of female names. \n",
    "\n",
    "#### Effect of undersampling the female set within the training data\n",
    "\n",
    "We wrote a function that took both the training dataset [train_set] and the list of names associated within the training dataset [tName], evaluated which gender's names there were more of and performed either an undersampling of the greater set or an oversampling of the smaller (based on input from the user). We then applied this function to the two lists before running our model again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'over' input below signifies whether the user wants to undersample or oversample the dataset (default undersample)\n",
    "def balance_train(train_set, tName, under = 1):\n",
    "    gender = []\n",
    "    for name,g in tName:\n",
    "        if g == \"female\":\n",
    "            gender.append(1)\n",
    "        else:\n",
    "            gender.append(0)\n",
    "    n_female = sum(gender)\n",
    "    n_male = len(gender) - n_female\n",
    "    if n_female == n_male:\n",
    "        return train_set, tName\n",
    "    elif n_female > n_male:\n",
    "        more = \"F\"\n",
    "        delta = n_female - n_male\n",
    "    else:\n",
    "        more = \"M\"\n",
    "        delta = n_male - n_female\n",
    "    \n",
    "    idx_males = []\n",
    "    idx_males = [i for i, val in enumerate(tName) if val[1] == \"male\"]\n",
    "    idx_females = []\n",
    "    idx_females = [i for i, val in enumerate(tName) if val[1] == \"female\"]\n",
    "    \n",
    "    remove = []\n",
    "    copy = []\n",
    "    if more == \"F\":\n",
    "        remove = idx_females\n",
    "        remove = remove[-delta:]\n",
    "        copy = idx_males\n",
    "    elif more == \"M\":\n",
    "        remove = idx_males\n",
    "        remove = remove[-delta:]\n",
    "        copy = idx_females\n",
    "    \n",
    "    if under == 1:\n",
    "        for index in reversed(remove):\n",
    "            del tName[index]\n",
    "            del train_set[index]\n",
    "    elif under == 0:\n",
    "        for i in range(0,delta):\n",
    "            tName.append(tName[copy[i]])\n",
    "            train_set.append(train_set[copy[i]])\n",
    "    return train_set, tName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.796\n",
      "Number of errors: 102\n"
     ]
    }
   ],
   "source": [
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "\n",
    "train_set, tName = balance_train(train_set, tName,1)\n",
    "\n",
    "nbClass4 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass4, devtest_set))\n",
    "\n",
    "preds4, errors4 = pred_calc(dtName, gender_features3, nbClass4)\n",
    "print('Number of errors:', len(errors4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Percent Correct</th>\n",
       "      <th>Percent Incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Females</td>\n",
       "      <td>78%</td>\n",
       "      <td>22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Males</td>\n",
       "      <td>81%</td>\n",
       "      <td>19%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Percent Correct Percent Incorrect\n",
       "0  Females             78%               22%\n",
       "1    Males             81%               19%"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsPred4, tsError4 = pred_calc(tsName, gender_features3,nbClass4)\n",
    "performance_table_pct = summ_table(allNames, tsPred4)\n",
    "performance_table_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of oversampling the male set within the training data\n",
    "For the oversampling of male data we wrote a similar function that evaluated how many fewer male names there were and appended that many copies of names from the lists themselves to even the numbers out. We again applied this function and re-ran the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.798\n",
      "Number of errors: 101\n"
     ]
    }
   ],
   "source": [
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "\n",
    "train_set, tName = balance_train(train_set, tName, 0)\n",
    "\n",
    "nbClass5 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass5, devtest_set))\n",
    "\n",
    "preds5, errors5 = pred_calc(dtName, gender_features3, nbClass5)\n",
    "print('Number of errors:', len(errors5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Percent Correct</th>\n",
       "      <th>Percent Incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Females</td>\n",
       "      <td>78%</td>\n",
       "      <td>22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Males</td>\n",
       "      <td>82%</td>\n",
       "      <td>18%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Percent Correct Percent Incorrect\n",
       "0  Females             78%               22%\n",
       "1    Males             82%               18%"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsPred5, tsError5 = pred_calc(tsName, gender_features3,nbClass5)\n",
    "summ_table(allNames, tsPred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the summary tables, both approaches to balancing the training dataset reduced the accuracy of predicting female names, but increased that of predicting male names. This is driven by the fact that the algorithm has fewer female names to determine patterns from, leading to less accurate patterns. This in turn increases the relative impact of the male-predictor patterns. \n",
    "\n",
    "#### Impact of original random_seed to split the data\n",
    "\n",
    "The names that make their way into the training set will obviously have an impact on how accurate a predictor model is. Below are a few result tables showing the difference in accuracy based on different initial train-test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_correct(allNames, tsPred):\n",
    "    tag = [name for name in tsPred if [name for (name, tag) in allNames]]\n",
    "    perform = []\n",
    "    for i in tsPred:\n",
    "        if (i[0] == 'male') & (i[1] == 'male'):\n",
    "            perform.append('correct male')\n",
    "        elif (i[0] == 'female') & (i[1] == 'female'):\n",
    "            perform.append('correct female')\n",
    "        elif (i[0] == 'male') & (i[1] == 'female'):\n",
    "            perform.append('incorrect male')\n",
    "        else:\n",
    "            perform.append('incorrect female')\n",
    "            \n",
    "    correct_male = perform.count('correct male')\n",
    "    correct_female = perform.count('correct female')\n",
    "    incorrect_female = perform.count('incorrect female')\n",
    "    incorrect_male = perform.count('incorrect male')\n",
    "    \n",
    "    female_pct_corr = correct_female / (correct_female + incorrect_female)\n",
    "    male_pct_corr = correct_male / (correct_male + incorrect_male)\n",
    "    \n",
    "    return female_pct_corr , male_pct_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03b\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Normal</th>        <th class=\"col_heading level0 col1\" >Undersampled</th>        <th class=\"col_heading level0 col2\" >Oversampled</th>    </tr>    <tr>        <th class=\"index_name level0\" >Seed</th>        <th class=\"index_name level1\" >Gender</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel0_row0\" class=\"row_heading level0 row0\" rowspan=2>582</th>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row0\" class=\"row_heading level1 row0\" >F</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow0_col0\" class=\"data row0 col0\" >85.2%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow0_col1\" class=\"data row0 col1\" >81.0%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow0_col2\" class=\"data row0 col2\" >81.0%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row1\" class=\"row_heading level1 row1\" >M</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow1_col0\" class=\"data row1 col0\" >78.8%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow1_col1\" class=\"data row1 col1\" >82.5%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow1_col2\" class=\"data row1 col2\" >82.5%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel0_row2\" class=\"row_heading level0 row2\" rowspan=2>257</th>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row2\" class=\"row_heading level1 row2\" >F</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow2_col0\" class=\"data row2 col0\" >81.5%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow2_col1\" class=\"data row2 col1\" >78.8%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow2_col2\" class=\"data row2 col2\" >78.8%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row3\" class=\"row_heading level1 row3\" >M</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow3_col0\" class=\"data row3 col0\" >73.1%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow3_col1\" class=\"data row3 col1\" >80.3%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow3_col2\" class=\"data row3 col2\" >80.3%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel0_row4\" class=\"row_heading level0 row4\" rowspan=2>886</th>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row4\" class=\"row_heading level1 row4\" >F</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow4_col0\" class=\"data row4 col0\" >79.7%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow4_col1\" class=\"data row4 col1\" >74.3%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow4_col2\" class=\"data row4 col2\" >74.3%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row5\" class=\"row_heading level1 row5\" >M</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow5_col0\" class=\"data row5 col0\" >77.0%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow5_col1\" class=\"data row5 col1\" >80.5%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow5_col2\" class=\"data row5 col2\" >80.5%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel0_row6\" class=\"row_heading level0 row6\" rowspan=2>983</th>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row6\" class=\"row_heading level1 row6\" >F</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow6_col0\" class=\"data row6 col0\" >80.5%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow6_col1\" class=\"data row6 col1\" >74.9%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow6_col2\" class=\"data row6 col2\" >74.9%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row7\" class=\"row_heading level1 row7\" >M</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow7_col0\" class=\"data row7 col0\" >76.4%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow7_col1\" class=\"data row7 col1\" >80.7%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow7_col2\" class=\"data row7 col2\" >80.7%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel0_row8\" class=\"row_heading level0 row8\" rowspan=2>198</th>\n",
       "                        <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row8\" class=\"row_heading level1 row8\" >F</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow8_col0\" class=\"data row8 col0\" >80.7%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow8_col1\" class=\"data row8 col1\" >77.0%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow8_col2\" class=\"data row8 col2\" >77.0%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03blevel1_row9\" class=\"row_heading level1 row9\" >M</th>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow9_col0\" class=\"data row9 col0\" >75.0%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow9_col1\" class=\"data row9 col1\" >79.9%</td>\n",
       "                        <td id=\"T_215e1922_bd96_11ea_8a74_b46bfcaaf03brow9_col2\" class=\"data row9 col2\" >79.9%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21bf77d2b88>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seeds = 5\n",
    "seeds = random.sample(range(0,1000),n_seeds)\n",
    "iterables = [seeds,['F','M']]\n",
    "index = pd.MultiIndex.from_product(iterables, names = ['Seed','Gender'])\n",
    "df = pd.DataFrame(np.zeros((n_seeds*2, 3)),index =index, columns = [\"Normal\",\"Undersampled\",\"Oversampled\"])\n",
    "counter = 0\n",
    "for seed in seeds:\n",
    "    random.seed(seed)\n",
    "    allNames = males + females\n",
    "    random.shuffle(allNames)\n",
    "    test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "    for i in range(0,3):\n",
    "        train_set2 = []\n",
    "        tname = []\n",
    "        if i == 0:\n",
    "            train_set2 = train_set\n",
    "        elif i == 1:\n",
    "            train_set2, tName = balance_train(train_set, tName, 1)\n",
    "        elif i == 2:\n",
    "            train_set2, tName = balance_train(train_set, tName, 0)\n",
    "            \n",
    "        nbClass = nltk.NaiveBayesClassifier.train(train_set2)\n",
    "        tsPred, tsError = pred_calc(tsName, gender_features3,nbClass)\n",
    "        f_pct, m_pct = pull_correct(allNames, tsPred)\n",
    "        df.iloc[counter][i] = f_pct\n",
    "        df.iloc[counter+1][i] = m_pct\n",
    "    allNames =[]\n",
    "    counter = counter + 2\n",
    "    \n",
    "df.style.format({\n",
    "    'Normal': '{:,.1%}'.format,\n",
    "    'Undersampled': '{:,.1%}'.format,\n",
    "    'Oversampled': '{:,.1%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the table above our female name accuracy changes significantly even just for the Normal training set (ranging anywhere from below 80% to above 85%) depending on the random seed chosen to split the data into train and test datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "1. D. M. Sidhu and P. M. Pexman. What’s in a name? sound symbolism and gender in first names. PLOS ONE, 10(5):e0126809, 2015.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
