{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUNY Data 620 - Web Analytics, Summer 2020  \n",
    "**Final Project**   \n",
    "**Prof:** Alain Ledon  \n",
    "**Members:** Misha Kollontai, Amber Ferger, Zach Alexander, Subhalaxmi Rout \n",
    "\n",
    "**Youtube Link:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "Your project should incorporate one or both of the two main themes of this course: network analysis and text processing. You need to show all of your work in a coherent workflow, and in a reproducible format, such as an IPython Notebook or an R Markdown document. If you are building a model or models, explain how you evaluate the “goodness” of the chosen model and parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Purpose\n",
    "\n",
    "For this project, we will be pulling twitter data related to the Coronavirus pandemic in the United States. Our primary objective will be to identify the relationship between city and overall sentiment towards covid. We will look at the average daily tweet sentiment for **NYC** (severe initial wave) and **New Orleans** (experiencing something of a second wave) to see if there are regional differences. From this, we would like to answer the following questions:\n",
    "\n",
    "* Is there a relationship between location-specific Covid-19 sentiment and the number of positive cases within that region?\n",
    "* Does positive sentiment preceed spikes in positive cases?\n",
    "\n",
    "As a secondary objective, we would like to identify relationships between major US cities by looking at shared tweet hashtags. We aim to create a network from these relationships where nodes represent cities and edges represent shared use of hashtags. In doing this, we would like to answer the following questions:\n",
    "\n",
    "* What issues (additional hashtags) are discussed in conjunction with Covid-19?\n",
    "* What differences in hashtag use is there across the country?\n",
    "* Are there certain cities that care about similar issues (additional hashtags)?\n",
    "\n",
    "As a stretch goal, we would also like to answer the question: Is there a relationship between location-specific Covid-19 hashtags and the number of positive cases within that region? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "#### Relevant Cities\n",
    "First, we generated a list of geocodes that related to the most populous city in each US state (plus DC). This data was pulled from the [1000 Largest US Cities By Population With Geographic Coordinates](https://public.opendatasoft.com/explore/dataset/1000-largest-us-cities-by-population-with-geographic-coordinates/table/?sort=-rank). \n",
    "\n",
    "\n",
    "#### Covid-Tweets\n",
    "Our initial plan was to use the Twitter API to pull in relevant tweets, but we later realized that the API only allows users to pull back 5 days worth of data. This being said, we turned to the [*GetOldTweets3*](https://pypi.org/project/GetOldTweets3/) package, which allowed us to return tweets with the following specifications:\n",
    "\n",
    "* **Date Range**: 3/8/2020 - 7/15/2020, pulled in biweekly groupings by city.\n",
    "* The tweet itself contains the word **Covid** or it is included in one of the hashtags.\n",
    "* The limit on the total number of tweets per API call is 1000 per date increment. Some of our cities had the full 1000 tweets while others contained less. \n",
    "\n",
    "Our final output includes: tweet text, additional hashtags, city coordinates, 'WEEK_START', 'WEEK_END'\n",
    "\n",
    "Please see the **tweetPull** notebook for more information about the the extraction of relevant tweets. \n",
    "\n",
    "\n",
    "#### Covid Case Numbers\n",
    "\n",
    "We will be using the Twitter API to scrape Tweet data, [John's Hopkins COVID-19 Data](https://github.com/CSSEGISandData/COVID-19) and [Wikipedia](https://en.wikipedia.org/wiki/COVID-19_pandemic_in_the_United_States) for the COVID-19 numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "1. Scrape Twitter data from 2 locations - perhaps NYC (severe initial wave) and New Orleans (experiencing something of a second wave)\n",
    "2. Pull coronavirus case numbers for the 2 locations in question\n",
    "3. Perform sentiment analyis on the tweets collected and aggregate them into an overall sentiment index for each day\n",
    "4. Plot timeseries of the sentiment index -vs- Coronavirus case numbers\n",
    "5. Indicate important moments on the timeline related to Covid-19 safety measures or announcements\n",
    "6. Investigate potential relationships between the two sets and compare the relationships from one city to another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "We will define the following functions:\n",
    "* **splitTags**: This will be used in splitting up the hashtags into separate entities. \n",
    "* **unpack_lat_long**: This will be used to generate separate lists for the latitude and longitude values from the city coordinates. \n",
    "* **createEdges**: This will be used to generate a final edge list that is based on shared tweet hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### sentiment analysis\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    neg = score['neg']\n",
    "    pos = score['pos']\n",
    "    neu = score['neu']\n",
    "    compound= score['compound']\n",
    "    \n",
    "    return [neg,pos,neu,compound, sentence]\n",
    "\n",
    "############### splitting hashtag groupings\n",
    "def splitTags(x,y):\n",
    "    return [(x,z) for z in y]\n",
    "\n",
    "############### split coordinates\n",
    "def unpack_lat_long(lat_long):\n",
    "    split = lat_long.split(',')\n",
    "    lat = split[0]\n",
    "    long = split[1]\n",
    "    return lat, long\n",
    "\n",
    "############### create edge list\n",
    "def createEdges(ls):    \n",
    "    productList = []\n",
    "    \n",
    "    for i in ls:\n",
    "        if len(i) >1:\n",
    "            productList.append(list(combinations(i,2)))\n",
    "    \n",
    "    return [val for sublist in productList for val in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "**TO DO: Explanation of twitter data pull**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and replace nulls\n",
    "tweets = pd.read_csv('Covid_Twitter_City_Data.csv', delimiter=',')\n",
    "tweets = tweets.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate sentiment analyzer, define function for sentiment output\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# sentiments to dataframe\n",
    "text = tweets['TEXT'].tolist()\n",
    "sentiments = [sentiment_analyzer_scores(s) for s in text]\n",
    "sentiments_df = pd.DataFrame(sentiments, columns = ['NEGATIVE_SCORE', 'POSITIVE_SCORE', 'NEUTRAL_SCORE', 'COMPOUND', 'SENTENCE'])\n",
    "\n",
    "# final dataframe with sentiments\n",
    "finalFrame = tweets.join(sentiments_df)\n",
    "finalFrame = finalFrame.iloc[:,1:-1]\n",
    "\n",
    "#finalFrame.groupby(['City']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>HASHTAGS</th>\n",
       "      <th>COORDS</th>\n",
       "      <th>WEEK_START</th>\n",
       "      <th>WEEK_END</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>NEGATIVE_SCORE</th>\n",
       "      <th>POSITIVE_SCORE</th>\n",
       "      <th>NEUTRAL_SCORE</th>\n",
       "      <th>COMPOUND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39294</th>\n",
       "      <td>Awesome, thanks again!!</td>\n",
       "      <td></td>\n",
       "      <td>38.9071923,-77.0368707</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Washington</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>646449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34658</th>\n",
       "      <td>Yes. THANKS Covid</td>\n",
       "      <td></td>\n",
       "      <td>41.8781136,-87.6297982</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2718782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.7456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>Thank God! #Covid_19</td>\n",
       "      <td>#Covid_19</td>\n",
       "      <td>40.7607793,-111.8910474</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Utah</td>\n",
       "      <td>191180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35536</th>\n",
       "      <td>WOW. #COVID__19</td>\n",
       "      <td>#COVID__19</td>\n",
       "      <td>43.6187102,-116.2146068</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Boise City</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>214237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13158</th>\n",
       "      <td>COVID Free</td>\n",
       "      <td></td>\n",
       "      <td>35.4675602,-97.5164276</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>610613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28393</th>\n",
       "      <td>Covid free</td>\n",
       "      <td></td>\n",
       "      <td>43.661471,-70.2553259</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>66318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7311</th>\n",
       "      <td>Covid kisses.</td>\n",
       "      <td></td>\n",
       "      <td>35.1495343,-90.0489801</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>653450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40743</th>\n",
       "      <td>COVID safe. Good thinking.</td>\n",
       "      <td></td>\n",
       "      <td>39.7390721,-75.5397878</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>71525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21842</th>\n",
       "      <td>Wow! That is excellent! Good for you!</td>\n",
       "      <td></td>\n",
       "      <td>45.7832856,-108.5006904</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Billings</td>\n",
       "      <td>Montana</td>\n",
       "      <td>109059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.9057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>Dear COVID-19,</td>\n",
       "      <td></td>\n",
       "      <td>44.4758825,-73.212072</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>42284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        TEXT    HASHTAGS  \\\n",
       "39294                Awesome, thanks again!!               \n",
       "34658                      Yes. THANKS Covid               \n",
       "5033                    Thank God! #Covid_19   #Covid_19   \n",
       "35536                        WOW. #COVID__19  #COVID__19   \n",
       "13158                             COVID Free               \n",
       "28393                             Covid free               \n",
       "7311                           Covid kisses.               \n",
       "40743             COVID safe. Good thinking.               \n",
       "21842  Wow! That is excellent! Good for you!               \n",
       "4439                         Dear COVID-19,                \n",
       "\n",
       "                        COORDS  WEEK_START    WEEK_END            City  \\\n",
       "39294   38.9071923,-77.0368707  2020-03-08  2020-07-15      Washington   \n",
       "34658   41.8781136,-87.6297982  2020-03-08  2020-07-15         Chicago   \n",
       "5033   40.7607793,-111.8910474  2020-03-08  2020-07-15  Salt Lake City   \n",
       "35536  43.6187102,-116.2146068  2020-03-08  2020-07-15      Boise City   \n",
       "13158   35.4675602,-97.5164276  2020-03-08  2020-07-15   Oklahoma City   \n",
       "28393    43.661471,-70.2553259  2020-03-08  2020-07-15        Portland   \n",
       "7311    35.1495343,-90.0489801  2020-03-08  2020-07-15         Memphis   \n",
       "40743   39.7390721,-75.5397878  2020-03-08  2020-07-15      Wilmington   \n",
       "21842  45.7832856,-108.5006904  2020-03-08  2020-07-15        Billings   \n",
       "4439     44.4758825,-73.212072  2020-03-08  2020-07-15      Burlington   \n",
       "\n",
       "                      State  Population  NEGATIVE_SCORE  POSITIVE_SCORE  \\\n",
       "39294  District of Columbia      646449             0.0           0.884   \n",
       "34658              Illinois     2718782             0.0           0.864   \n",
       "5033                   Utah      191180             0.0           0.830   \n",
       "35536                 Idaho      214237             0.0           0.792   \n",
       "13158              Oklahoma      610613             0.0           0.767   \n",
       "28393                 Maine       66318             0.0           0.767   \n",
       "7311              Tennessee      653450             0.0           0.767   \n",
       "40743              Delaware       71525             0.0           0.744   \n",
       "21842               Montana      109059             0.0           0.738   \n",
       "4439                Vermont       42284             0.0           0.722   \n",
       "\n",
       "       NEUTRAL_SCORE  COMPOUND  \n",
       "39294          0.116    0.8217  \n",
       "34658          0.136    0.7456  \n",
       "5033           0.170    0.5983  \n",
       "35536          0.208    0.5859  \n",
       "13158          0.233    0.5106  \n",
       "28393          0.233    0.5106  \n",
       "7311           0.233    0.5106  \n",
       "40743          0.256    0.7003  \n",
       "21842          0.262    0.9057  \n",
       "4439           0.278    0.3818  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalFrame.sort_values(by=['POSITIVE_SCORE'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Network\n",
    "* **Nodes**: Cities, **TO DO: color: sentiment, size: portion of population affected by covid**\n",
    "* **Edges**: Shared Hashtags, **TO DO: edge weights: number of shared hashtags**\n",
    "\n",
    "#### Hashtags by Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], ['#CX', '#COVID', '#custserv']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hashtags & coordinates for each record\n",
    "hashtags = tweets['HASHTAGS'].tolist()\n",
    "coords = tweets['COORDS'].tolist()\n",
    "sepHash = [i.split() for i in hashtags]\n",
    "sepHash[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example output from the hashtag #FollowTheScience:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['38.9071923,-77.0368707',\n",
       " '41.8781136,-87.6297982',\n",
       " '39.9525839,-75.1652215',\n",
       " '34.7464809,-92.2895948',\n",
       " '39.7392358,-104.990251',\n",
       " '47.6062095,-122.3320708',\n",
       " '34.0522342,-118.2436849',\n",
       " '39.9611755,-82.9987942']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set of all coordinates with individual hashtag\n",
    "coordTag = [splitTags(i,j) for i,j in list(zip(coords,sepHash)) if len(j)> 0]\n",
    "flattened = [val for sublist in coordTag for val in sublist]\n",
    "finalHash = set(flattened)\n",
    "\n",
    "# create a dictionary of each hashtag with the city coordinates\n",
    "tempDict = {}\n",
    "for i,j in finalHash:\n",
    "    if j not in tempDict:\n",
    "        tempDict[j]= [i]\n",
    "    else:\n",
    "        tempDict[j].append(i)\n",
    "        \n",
    "# remove covid hashtags from dictionary\n",
    "tagsToRemove = ['#covid_19', '#COVID19', '#COVID2019', '#COVID_19', '#COVID__19', '#COVID', '#CoronavirusUSA', '#CV19',\n",
    "                '#COVD19', '#Covid_19', '#CORONAVIRUS', '#Coronavirus', '#CoronavirusCOVID', '#Corona', '#Coronovirus',\n",
    "               '#CoronavirusOubreak', '#CoronavirusPandemic', '#CoronavirusOutbreak', '#CoronavirusPandemic', '#coronavirus', \n",
    "                '#Covid19', '#covid', '#Covid', '#covid19', '#pandemic', '#corona']\n",
    "\n",
    "for k in tagsToRemove:\n",
    "    tempDict.pop(k, None)\n",
    "\n",
    "print('Example output from the hashtag #FollowTheScience:')\n",
    "tempDict['#FollowTheScience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business:  15\n",
      "stay home:  13\n",
      "both:  5\n"
     ]
    }
   ],
   "source": [
    "len(tempDict['#VoteBlueToSaveAmerica2020'])\n",
    "#sorted(tempDict['#BlackLivesMatter'])\n",
    "\n",
    "#list(set(tempDict['#VoteBlueToSaveAmerica2020']) & set(tempDict['#BlackLivesMatter']))\n",
    "\n",
    "\n",
    "print('business: ' , len(tempDict['#business']))\n",
    "print('stay home: ' , len(tempDict['#stayhome']))\n",
    "print('both: ', len(set(tempDict['#business']) & set(tempDict['#stayhome'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Hashtags \n",
    "Let's take a look at the hashtags used in the highest number of cities. #WearAMask and #COVIDIOTS in particular stand out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>#WearAMask</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>#COVIDIOTS</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>#TMobileTuesdays</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#SmartNews</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>#contest</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>#TrumpVirus</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>#SocialDistancing</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>#BlackLivesMatter</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>#MaskUp</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>#WearADamnMask</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>#Florida</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#COVIDIDIOTS</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>#healthcare</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>#staysafe</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>#facemask</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>#Trump</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>#BREAKING</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>#love</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>#wearamask</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>#education</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>#TrumpLiesAmericansDie</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>#SchoolReopening</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>#DrFauci</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>#ProtectPassengers</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>#testing</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>#lockdown</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>#CoronaVirusUpdates</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>#MedTwitter</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>#Fauci</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>#vaccine</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>#TrumpIsANationalDisgrace</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>#StayHome</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>#StaySafe</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>#NBA</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>#BLM</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>#IStandWithFauci</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>#Masks</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>#mask</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>#business</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>#MAGA</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>#socialdistancing</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>#s</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>#VoteBlueToSaveAmerica2020</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>#tuesdayvibes</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>#NFL</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>#facemasks</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>#masks</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>#USA</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>#stayhome</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>#AmeripriseResearch</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>#coronavaccine</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>#health</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>#GOP</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>#NewYork</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>#TrumpGolfsAmericansDie</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>#Trump2020</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>#mentalhealth</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>#marketing</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>#Quarantine</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>#quarantine</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Hashtag  Cities\n",
       "81                    #WearAMask      41\n",
       "135                   #COVIDIOTS      32\n",
       "948             #TMobileTuesdays      28\n",
       "2                     #SmartNews      27\n",
       "334                     #contest      27\n",
       "385                  #TrumpVirus      27\n",
       "2655           #SocialDistancing      26\n",
       "407            #BlackLivesMatter      26\n",
       "75                       #MaskUp      25\n",
       "359               #WearADamnMask      25\n",
       "984                     #Florida      24\n",
       "7                   #COVIDIDIOTS      23\n",
       "472                  #healthcare      23\n",
       "1063                   #staysafe      21\n",
       "654                    #facemask      20\n",
       "1347                      #Trump      19\n",
       "582                    #BREAKING      19\n",
       "391                        #love      19\n",
       "99                    #wearamask      18\n",
       "353                   #education      17\n",
       "1632      #TrumpLiesAmericansDie      17\n",
       "446             #SchoolReopening      17\n",
       "1369                    #DrFauci      17\n",
       "356           #ProtectPassengers      17\n",
       "1055                    #testing      16\n",
       "1333                   #lockdown      16\n",
       "174          #CoronaVirusUpdates      16\n",
       "911                  #MedTwitter      16\n",
       "718                       #Fauci      16\n",
       "150                     #vaccine      16\n",
       "113    #TrumpIsANationalDisgrace      16\n",
       "417                    #StayHome      15\n",
       "103                    #StaySafe      15\n",
       "871                         #NBA      15\n",
       "58                          #BLM      15\n",
       "1093            #IStandWithFauci      15\n",
       "173                       #Masks      15\n",
       "520                        #mask      15\n",
       "188                    #business      15\n",
       "1081                       #MAGA      14\n",
       "1137           #socialdistancing      14\n",
       "376                           #s      14\n",
       "598   #VoteBlueToSaveAmerica2020      14\n",
       "115                #tuesdayvibes      14\n",
       "724                         #NFL      14\n",
       "875                   #facemasks      14\n",
       "415                       #masks      14\n",
       "35                          #USA      13\n",
       "1016                   #stayhome      13\n",
       "868          #AmeripriseResearch      13\n",
       "576               #coronavaccine      13\n",
       "629                      #health      12\n",
       "643                         #GOP      12\n",
       "379                     #NewYork      12\n",
       "2361     #TrumpGolfsAmericansDie      12\n",
       "1681                  #Trump2020      12\n",
       "1012               #mentalhealth      12\n",
       "23                    #marketing      12\n",
       "1462                 #Quarantine      12\n",
       "521                  #quarantine      11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top hashtags\n",
    "hsh = []\n",
    "ties = []\n",
    "for key, value in tempDict.items():\n",
    "    hsh.append(key)\n",
    "    ties.append(len(value))\n",
    "Hash_Ties = pd.DataFrame()\n",
    "Hash_Ties['Hashtag'] = hsh\n",
    "Hash_Ties['Cities'] = ties\n",
    "Hash_Ties = Hash_Ties.sort_values(by=['Cities'],ascending = False)\n",
    "Hash_Ties.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Edge: ('38.9071923,-77.0368707', '41.6005448,-93.6091064')\n"
     ]
    }
   ],
   "source": [
    "#### Final Edges\n",
    "# combining all elements in the dictionary values into separate node connections\n",
    "coordPairs = list(tempDict.values())\n",
    "finalPairs = createEdges(coordPairs)\n",
    "\n",
    "print('Example Edge:', finalPairs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['43.661471,-70.2553259',\n",
       " '40.7127837,-74.0059413',\n",
       " '41.6005448,-93.6091064',\n",
       " '30.3321838,-81.655651',\n",
       " '41.8781136,-87.6297982',\n",
       " '39.7390721,-75.5397878',\n",
       " '35.0853336,-106.6055534',\n",
       " '33.7489954,-84.3879824',\n",
       " '42.331427,-83.0457538',\n",
       " '40.735657,-74.1723667',\n",
       " '42.3600825,-71.0588801',\n",
       " '34.0007104,-81.0348144',\n",
       " '38.9071923,-77.0368707',\n",
       " '36.8529263,-75.977985',\n",
       " '61.2180556,-149.9002778',\n",
       " '35.2270869,-80.8431267']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into 2 subnetworks\n",
    "magaTweets = tempDict['#MAGA']\n",
    "tindTweets = tempDict['#TrumpIsANationalDisgrace']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate lists for latitude and longitude\n",
    "temp= tempDict['#WearAMask']\n",
    "WearMask_lat = []\n",
    "WearMask_long = []\n",
    "for city in temp:\n",
    "    lat, long = unpack_lat_long(city)\n",
    "    WearMask_lat.append(round(float(lat),2))\n",
    "    WearMask_long.append(round(float(long),2))\n",
    "WearMask_long[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(12, 8) ) \n",
    "#m = Basemap(width=6000000,height=4500000,resolution='c',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)\n",
    "m = Basemap(\n",
    "        projection='merc',\n",
    "        llcrnrlon=-130,\n",
    "        llcrnrlat=25,\n",
    "        urcrnrlon=-60,\n",
    "        urcrnrlat=50,\n",
    "        lat_ts=0,\n",
    "        resolution='i',\n",
    "        suppress_ticks=True)\n",
    "\n",
    "mx, my = m(WearMask_long,WearMask_lat)\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(temp)\n",
    "pos = {}\n",
    "i = 0\n",
    "for city in temp:\n",
    "    \n",
    "    pos[city] = (mx[i],my[i])\n",
    "    i+=1\n",
    "    \n",
    "nx.draw_networkx(G,pos, node_size = 200, node_color = 'red',with_labels = False)\n",
    "m.drawcoastlines(linewidth=0.5)\n",
    "m.fillcontinents(color='tan',lake_color='lightblue')\n",
    "# draw parallels and meridians.\n",
    "m.drawparallels(np.arange(-90.,91.,15.),labels=[True,True,False,False],dashes=[2,2])\n",
    "m.drawmeridians(np.arange(-180.,181.,15.),labels=[False,False,False,True],dashes=[2,2])\n",
    "m.drawmapboundary(fill_color='lightblue')\n",
    "m.drawcountries(linewidth=2, linestyle='solid', color='k' ) \n",
    "m.drawstates(linewidth=0.5, linestyle='solid', color='k')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Weights\n",
    "https://www.geeksforgeeks.org/python-program-to-count-duplicates-in-a-list-of-tuples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scraping Twitter Data from New York City & New Orleans\n",
    "\n",
    "As a first step, we decided to scrape tweets from two locations, New York City and New Orleans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading in the tweets from NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('covid_tweets.csv', delimiter='\\t')\n",
    "tweets['City'] = 'NYC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Pulling coronavirus case numbers for both locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_cases = pd.read_csv('confirmed_cases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering for NYC cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After locating the correct county FIPS number for New York City, we were able to filter the pandas dataframe to only include this row. Additionally, we transposed this row to ensure we had one column designated for the date and another for the number of confirmed cases for that corresponding date. Finally, we made sure to reset the index and adjust the date type in order to be able to show our visuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_filtered = covid_cases[covid_cases['FIPS'] == 36061]\n",
    "df = cases_filtered.iloc[:, 11:186:1]\n",
    "\n",
    "df = df.transpose().reset_index()\n",
    "df = df.rename(columns={'index': 'Date', 1863: \"Confirmed_Cases\"})\n",
    "\n",
    "nyc_time_series = pd.DataFrame(df, columns = ['Date','Confirmed_Cases'])\n",
    "nyc_time_series['Date'] = pd.to_datetime(nyc_time_series['Date'], format='%m/%d/%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick look at the filtered dataset with just NYC cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_time_series.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to find the number of new cases per day, we can utilize our confirmed cases column to take the difference between the current day and the previous day. Additionally, for our visualization, we can take the 7-day average of new cases and plot this as well, in order to obtain a better view of trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_newcases(df):\n",
    "    df['New_Cases'] = 'NA'\n",
    "    for i in range(0, len(df['Confirmed_Cases'])):\n",
    "        if i == 0:\n",
    "            df['New_Cases'][i] = 0\n",
    "        else:\n",
    "            df['New_Cases'][i] = df['Confirmed_Cases'][i] - df['Confirmed_Cases'][i-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sevenday(df):\n",
    "    df['Seven_Day_Avg'] = 'NA'\n",
    "    for i in range(0, len(df['Confirmed_Cases'])):\n",
    "        if i < 8:\n",
    "            df['Seven_Day_Avg'][i] = 0\n",
    "        else:\n",
    "            weekly = []\n",
    "            for y in range(0,7):\n",
    "                weekly.append(df['New_Cases'][i-y])\n",
    "            df['Seven_Day_Avg'][i] = sum(weekly) / 7\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_newcases(nyc_time_series)\n",
    "df = add_sevenday(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the `New Cases` and `Seven Day Average` columns, we can create a plot to show the case counts in New York City:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawNewCases(df, title, fignum, var):\n",
    "    var = plt.figure(fignum, figsize=(16,8))\n",
    "    plt.bar(df['Date'], df['New_Cases'], color='indianred', alpha=0.4)\n",
    "    plt.plot(df['Date'], df['Seven_Day_Avg'], c='indianred', linewidth=2)\n",
    "    plt.plot(legend=None)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Number of New Cases')\n",
    "    plt.gca().xaxis.set_major_formatter(fmt)\n",
    "    var.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = mdates.MonthLocator()\n",
    "fmt = mdates.DateFormatter('%B')\n",
    "\n",
    "nyc_time_series = pd.DataFrame(df, columns = ['Date','Confirmed_Cases', 'New_Cases', 'Seven_Day_Avg'])\n",
    "nyc_time_series['Date'] = pd.to_datetime(nyc_time_series['Date'], format='%m/%d/%y')\n",
    "\n",
    "drawNewCases(nyc_time_series, 'Number of new COVID-19 cases in New York City (Daily)', 1, 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering for New Orleans Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_filtered_newo = covid_cases[covid_cases['FIPS'] == 22071]\n",
    "\n",
    "\n",
    "df_newo = cases_filtered_newo.iloc[:, 11:186:1]\n",
    "\n",
    "df_newo = df_newo.transpose().reset_index()\n",
    "df_newo = df_newo.rename(columns={'index': 'Date', 1153: \"Confirmed_Cases\"})\n",
    "\n",
    "newo_time_series = pd.DataFrame(df_newo, columns = ['Date','Confirmed_Cases'])\n",
    "newo_time_series['Date'] = pd.to_datetime(newo_time_series['Date'], format='%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newo_time_series.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newo = add_newcases(newo_time_series)\n",
    "df_newo = add_sevenday(df_newo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newo_time_series = pd.DataFrame(df_newo, columns = ['Date','Confirmed_Cases', 'New_Cases', 'Seven_Day_Avg'])\n",
    "newo_time_series['Date'] = pd.to_datetime(newo_time_series['Date'], format='%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawNewCases(newo_time_series, 'Number of new COVID-19 cases in New Orleans (Daily)', 2, 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note from Zach**: Will remove this commented-out code later (see below), but thought I'd leave it just in case it'll be helpful for future visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locator = mdates.MonthLocator()\n",
    "# fmt = mdates.DateFormatter('%B')\n",
    "\n",
    "\n",
    "# plt.plot(nyc_time_series['Date'], nyc_time_series['Confirmed_Cases'], c='indianred')\n",
    "# plt.plot(legend=None)\n",
    "# plt.title('Number of Confirmed COVID-19 Cases in New York City')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Number of Confirmed Cases')\n",
    "# plt.gca().xaxis.set_major_formatter(fmt)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
